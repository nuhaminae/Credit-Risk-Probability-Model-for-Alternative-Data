{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytest\n",
    "import os, sys\n",
    "\n",
    "# Add project path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Import your FraudDetectionPipeline class\n",
    "from scripts._02_Feature_Engineering import FraudDetectionPipeline\n",
    "\n",
    "# Use the previously defined mock_df and setup_pipeline fixture\n",
    "mock_data = {\n",
    "    'TransactionId': [1, 2, 3, 4, 5],\n",
    "    'CustomerId': [101, 102, 101, 103, 102],\n",
    "    'AccountId': [201, 202, 201, 203, 304], \n",
    "    'SubscriptionId': [301, 302, 301, 303, 304], \n",
    "    'ProductId': ['ProdA', 'ProdB', 'ProdA', 'ProdC', 'ProdD'], \n",
    "    'ProductCategory': ['Cat1', 'Cat2', 'Cat1', 'Cat3', 'Cat4'], \n",
    "    'ChannelId': ['Web', 'Mobile', 'Web', 'Web', 'Mobile'],\n",
    "    'Amount': [100.0, 50.0, 120.0, 200.0, 60.0],\n",
    "    'Value': [100.0, 50.0, 120.0, 200.0, 60.0],\n",
    "    'CurrencyCode': ['AMZ']*5, \n",
    "    'CountryCode': ['ZYZ']*5, \n",
    "    'ResultCode': [0, 1, 0, 0, 1],\n",
    "    'BatchId': [1001, 1002, 1001, 1003, 1004], \n",
    "    'TransactionStartTime': pd.date_range(['2023-01-01 10:00:00', '2023-01-01 11:00:00', \n",
    "                                        '2023-01-02 10:30:00', '2023-01-02 12:00:00', \n",
    "                                        '2023-01-03 09:00:00']),\n",
    "    'ProviderId': ['ProvX', 'ProvY', 'ProvX', 'ProvZ', 'ProvA'], \n",
    "    'PricingStrategy': [1, 2, 1, 3, 4], \n",
    "    'FraudResult': [0, 1, 0, 0, 1] \n",
    "}\n",
    "\n",
    "mock_df = pd.DataFrame(mock_data)\n",
    "mock_df['TransactionStartTime'] = pd.to_datetime(mock_df['TransactionStartTime'])\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def setup_pipeline(tmp_path_factory):\n",
    "    \"\"\"Fixture to create a temporary CSV file and a pipeline instance.\"\"\"\n",
    "    temp_dir = tmp_path_factory.mktemp(\"data\")\n",
    "    csv_path = temp_dir / \"mock_data.csv\"\n",
    "    mock_df.to_csv(csv_path, index=False)\n",
    "\n",
    "    pipeline = FraudDetectionPipeline(df_path=str(csv_path), \n",
    "                                    plot_path=str(tmp_path_factory.mktemp(\"plots\")), \n",
    "                                    mdl_dir=str(tmp_path_factory.mktemp(\"models\")), \n",
    "                                    df_dir=str(tmp_path_factory.mktemp(\"processed_data\")))\n",
    "    yield pipeline\n",
    "    # Cleanup is handled automatically by tmp_path_factory\n",
    "\n",
    "def test_woe_transformation(setup_pipeline):\n",
    "    \"\"\"Tests the compute_monotonic_breaks, compute_categorical_breaks, and apply_woe_transformation methods.\"\"\"\n",
    "    pipeline = setup_pipeline\n",
    "    pipeline.load_and_split_data()\n",
    "\n",
    "    # Test compute_monotonic_breaks\n",
    "    pipeline.compute_monotonic_breaks()\n",
    "    assert isinstance(pipeline.breaks, dict)\n",
    "    numeric_vars_after_load = [col for col in pipeline.numeric_vars if col in pipeline.train.columns]\n",
    "\n",
    "    for var in numeric_vars_after_load:\n",
    "        assert var in pipeline.breaks\n",
    "        assert isinstance(pipeline.breaks[var], list)\n",
    "\n",
    "    # Test compute_categorical_breaks\n",
    "    pipeline.compute_categorical_breaks()\n",
    "    assert isinstance(pipeline.breaks, dict)\n",
    "    for var in pipeline.categorical_vars:\n",
    "        assert var in pipeline.breaks\n",
    "        assert isinstance(pipeline.breaks[var], dict) \n",
    "\n",
    "    # Test apply_woe_transformation\n",
    "    pipeline.apply_woe_transformation()\n",
    "    assert pipeline.bins_adj is not None\n",
    "    assert isinstance(pipeline.train_woe, pd.DataFrame)\n",
    "    assert isinstance(pipeline.test_woe, pd.DataFrame)\n",
    "\n",
    "    # Check WOE column names\n",
    "    woe_cols_train = [col for col in pipeline.train_woe.columns if col.endswith('_woe')]\n",
    "    woe_cols_test = [col for col in pipeline.test_woe.columns if col.endswith('_woe')]\n",
    "\n",
    "    # Check if all relevant columns have a WOE counterpart\n",
    "    all_transformed_vars = numeric_vars_after_load + [col for col in pipeline.categorical_vars if col in pipeline.train.columns]\n",
    "    # The number of WOE columns should match the number of original variables used for binning\n",
    "    assert len(woe_cols_train) == len(pipeline.breaks)\n",
    "    assert len(woe_cols_test) == len(pipeline.breaks)\n",
    "\n",
    "\n",
    "    # Check number of rows\n",
    "    assert len(pipeline.train_woe) == len(pipeline.train)\n",
    "    assert len(pipeline.test_woe) == len(pipeline.test)\n",
    "\n",
    "    # Check data types of WOE columns\n",
    "    for col in woe_cols_train:\n",
    "        assert pd.api.types.is_float_dtype(pipeline.train_woe[col]) or pd.api.types.is_integer_dtype(pipeline.train_woe[col])\n",
    "    for col in woe_cols_test:\n",
    "        assert pd.api.types.is_float_dtype(pipeline.test_woe[col]) or pd.api.types.is_integer_dtype(pipeline.test_woe[col])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".credvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
